{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to timm-pretrained model, then turn into series of unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_prisma.configs import HookedViTConfig\n",
    "from vit_prisma.models.base_vit import HookedViT\n",
    "\n",
    "import timm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model vit_base_patch16_224 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "prisma_model = HookedViT.from_pretrained(\"vit_base_patch16_224\", \n",
    "                                         center_writing_weights=False, \n",
    "                                         fold_ln=False, \n",
    "                                         fold_value_biases=False,\n",
    "                                         use_attn_scale=False,\n",
    "                                         use_split_qkv_input=True,\n",
    ")\n",
    "timm_model = timm.create_model('vit_base_patch16_224', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize the images to [-1, 1]\n",
    "    # Resize to 224 x 224\n",
    "    transforms.Resize((224, 224))\n",
    "])\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sonia.joseph/vit-phase-transitions/env/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([1, 196, 768])\n",
      "hook_pos_embed torch.Size([1, 197, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.0.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.0.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.0.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.0.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.0.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.1.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.1.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.1.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.1.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.1.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.1.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.1.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.1.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.1.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.1.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.1.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.1.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.1.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.1.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.1.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.1.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.1.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.2.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.2.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.2.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.2.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.2.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.2.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.2.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.2.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.2.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.2.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.2.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.2.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.2.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.2.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.2.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.2.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.2.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.3.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.3.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.3.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.3.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.3.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.3.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.3.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.3.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.3.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.3.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.3.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.3.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.3.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.3.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.3.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.3.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.3.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.4.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.4.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.4.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.4.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.4.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.4.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.4.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.4.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.4.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.4.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.4.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.4.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.4.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.4.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.4.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.4.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.4.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.5.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.5.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.5.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.5.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.5.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.5.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.5.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.5.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.5.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.5.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.5.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.5.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.5.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.5.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.5.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.5.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.5.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.6.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.6.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.6.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.6.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.6.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.6.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.6.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.6.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.6.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.6.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.6.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.6.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.6.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.6.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.6.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.6.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.6.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.7.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.7.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.7.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.7.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.7.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.7.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.7.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.7.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.7.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.7.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.7.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.7.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.7.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.7.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.7.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.7.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.7.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.8.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.8.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.8.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.8.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.8.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.8.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.8.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.8.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.8.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.8.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.8.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.8.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.8.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.8.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.8.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.8.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.8.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.9.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.9.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.9.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.9.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.9.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.9.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.9.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.9.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.9.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.9.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.9.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.9.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.9.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.9.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.9.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.9.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.9.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.10.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.10.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.10.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.10.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.10.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.10.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.10.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.10.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.10.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.10.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.10.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.10.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.10.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.10.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.10.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.10.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.10.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.11.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.11.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.11.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.11.attn.hook_q torch.Size([1, 197, 12, 64])\n",
      "blocks.11.attn.hook_k torch.Size([1, 197, 12, 64])\n",
      "blocks.11.attn.hook_v torch.Size([1, 197, 12, 64])\n",
      "blocks.11.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.11.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.11.attn.hook_z torch.Size([1, 197, 12, 64])\n",
      "blocks.11.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.11.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.11.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.11.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.11.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.11.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.11.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.11.hook_resid_post torch.Size([1, 197, 768])\n",
      "ln_final.hook_scale torch.Size([1, 197, 1])\n",
      "ln_final.hook_normalized torch.Size([1, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "image, label = next(iter(testloader))\n",
    "output, cache = prisma_model.run_with_cache(image)\n",
    "\n",
    "for key in cache.keys():\n",
    "    print(key, cache[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.patch_embed.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "activations[0].shape\n",
    "\n",
    "assert torch.allclose(activations[0], cache['embed'][0])\n",
    "assert torch.all(activations[0] == cache['embed'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.pos_drop.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "assert torch.allclose(activations[0], cache['blocks.0.hook_resid_pre'], atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LayerNorm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer\n",
    "\n",
    "import einops \n",
    "\n",
    "\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.blocks[0].norm1.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "\n",
    "# Assert equal to the first layer\n",
    "assert torch.allclose(activations[0], cache['blocks.0.ln1.hook_normalized'][0], atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compare qkv weights\n",
    "QKV = timm_model.blocks[0].attn.qkv.weight\n",
    "W_Q, W_K, W_V = torch.tensor_split(QKV, 3, dim=0)\n",
    "t_Q = einops.rearrange(W_Q, \"(i h) m->h m i\", h=12)\n",
    "t_K = einops.rearrange(W_K, \"(i h) m->h m i\", h=12)\n",
    "t_V = einops.rearrange(W_V, \"(i h) m->h m i\", h=12)\n",
    "\n",
    "p_Q = prisma_model.blocks[0].attn.W_Q\n",
    "p_K = prisma_model.blocks[0].attn.W_K\n",
    "p_V = prisma_model.blocks[0].attn.W_V\n",
    "\n",
    "assert torch.allclose(p_Q, t_Q, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "assert torch.allclose(p_K, t_K, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "assert torch.allclose(p_V, t_V, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "\n",
    "# qkv bias\n",
    "bias_QKV = timm_model.blocks[0].attn.qkv.bias\n",
    "\n",
    "b_Q, b_K, b_V = torch.tensor_split(bias_QKV, 3, dim=0)\n",
    "\n",
    "bt_Q = einops.rearrange(b_Q, \"(i h) -> h i\", h=12)\n",
    "bt_K = einops.rearrange(b_K, \"(i h) -> h i\", h=12)\n",
    "bt_V = einops.rearrange(b_V, \"(i h) -> h i\", h=12)\n",
    "\n",
    "bp_Q = prisma_model.blocks[0].attn.b_Q\n",
    "bp_K = prisma_model.blocks[0].attn.b_K\n",
    "bp_V = prisma_model.blocks[0].attn.b_V\n",
    "\n",
    "assert torch.allclose(bp_Q, bt_Q, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "assert torch.allclose(bp_K, bt_K, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "assert torch.allclose(bp_V, bt_V, atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 197, 64])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Activations differ more than the allowed tolerance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m hook_handle\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(activations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(activations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks.0.attn.hook_q\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m), atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActivations differ more than the allowed tolerance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Activations differ more than the allowed tolerance"
     ]
    }
   ],
   "source": [
    "# First layer\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.blocks[0].attn.q_norm.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "print(activations[0][0].shape)\n",
    "\n",
    "\n",
    "assert torch.allclose(activations[0][0], cache['blocks.0.attn.hook_q'][0].permute(1,0,2), atol=1e-2), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 197, 64])\n",
      "torch.Size([12, 197, 64])\n"
     ]
    }
   ],
   "source": [
    " cache['blocks.0.attn.hook_k'][0].shape\n",
    "print(activations[0].shape)\n",
    "print(cache['blocks.0.attn.hook_k'][0].permute(1,0,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 197, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (768) must match the size of tensor b (64) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(activations[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m768\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m hook_handle\u001b[38;5;241m.\u001b[39mremove()\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblocks.0.attn.hook_k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActivations differ more than the allowed tolerance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (768) must match the size of tensor b (64) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# First layer\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.blocks[0].attn.qkv.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "\n",
    "print(cache['blocks.0.attn.hook_k'][0].permute(1,0,2).shape)\n",
    "\n",
    "q, k, v = torch.split(activations[0], 768, dim=-1)\n",
    "\n",
    "hook_handle.remove()\n",
    "\n",
    "assert torch.allclose(k, cache['blocks.0.attn.hook_k'][0].permute(1,0,2), atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Activations differ more than the allowed tolerance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m timm_output \u001b[38;5;241m=\u001b[39m timm_model(image)\n\u001b[1;32m      8\u001b[0m hook_handle\u001b[38;5;241m.\u001b[39mremove()\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(activations[\u001b[38;5;241m0\u001b[39m], cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks.0.hook_attn_out\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActivations differ more than the allowed tolerance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Activations differ more than the allowed tolerance"
     ]
    }
   ],
   "source": [
    "# First layer\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.blocks[0].attn.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "assert torch.allclose(activations[0], cache['blocks.0.hook_attn_out'][0], atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prisma_model.cfg.use_split_qkv_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
