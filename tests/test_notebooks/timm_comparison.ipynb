{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to timm-pretrained model, then turn into series of unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_prisma.configs import HookedViTConfig\n",
    "from vit_prisma.models.base_vit import HookedViT\n",
    "\n",
    "import timm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model vit_base_patch16_224 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "prisma_model = HookedViT.from_pretrained(\"vit_base_patch16_224\", \n",
    "                                         center_writing_weights=False, \n",
    "                                         fold_ln=False, \n",
    "                                         fold_value_biases=False,\n",
    "                                         use_attn_scale=False,\n",
    "                                         use_attn_in=True,\n",
    ")\n",
    "timm_model = timm.create_model('vit_base_patch16_224', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/170498071 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:01<00:00, 103360609.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize the images to [-1, 1]\n",
    "    # Resize to 224 x 224\n",
    "    transforms.Resize((224, 224))\n",
    "])\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sonia.joseph/vit-phase-transitions/env/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([1, 196, 768])\n",
      "hook_pos_embed torch.Size([1, 197, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.0.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.0.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.0.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.0.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.0.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.0.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.0.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.0.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.0.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.1.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.1.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.1.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.1.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.1.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.1.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.1.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.1.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.1.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.1.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.1.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.1.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.1.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.1.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.1.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.1.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.1.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.1.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.1.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.2.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.2.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.2.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.2.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.2.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.2.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.2.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.2.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.2.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.2.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.2.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.2.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.2.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.2.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.2.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.2.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.2.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.2.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.2.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.3.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.3.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.3.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.3.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.3.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.3.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.3.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.3.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.3.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.3.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.3.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.3.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.3.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.3.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.3.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.3.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.3.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.3.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.3.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.4.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.4.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.4.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.4.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.4.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.4.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.4.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.4.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.4.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.4.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.4.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.4.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.4.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.4.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.4.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.4.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.4.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.4.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.4.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.5.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.5.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.5.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.5.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.5.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.5.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.5.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.5.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.5.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.5.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.5.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.5.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.5.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.5.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.5.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.5.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.5.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.5.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.5.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.6.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.6.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.6.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.6.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.6.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.6.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.6.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.6.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.6.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.6.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.6.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.6.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.6.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.6.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.6.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.6.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.6.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.6.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.6.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.7.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.7.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.7.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.7.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.7.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.7.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.7.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.7.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.7.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.7.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.7.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.7.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.7.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.7.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.7.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.7.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.7.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.7.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.7.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.8.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.8.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.8.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.8.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.8.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.8.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.8.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.8.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.8.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.8.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.8.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.8.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.8.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.8.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.8.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.8.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.8.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.8.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.8.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.9.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.9.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.9.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.9.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.9.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.9.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.9.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.9.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.9.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.9.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.9.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.9.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.9.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.9.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.9.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.9.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.9.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.9.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.9.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.10.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.10.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.10.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.10.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.10.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.10.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.10.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.10.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.10.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.10.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.10.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.10.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.10.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.10.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.10.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.10.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.10.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.10.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.10.hook_resid_post torch.Size([1, 197, 768])\n",
      "blocks.11.hook_resid_pre torch.Size([1, 197, 768])\n",
      "blocks.11.hook_attn_in torch.Size([1, 197, 768])\n",
      "blocks.11.ln1.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.11.ln1.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.11.attn.hook_qkv torch.Size([3, 1, 12, 197, 64])\n",
      "blocks.11.attn.hook_q torch.Size([1, 12, 197, 64])\n",
      "blocks.11.attn.hook_k torch.Size([1, 12, 197, 64])\n",
      "blocks.11.attn.hook_v torch.Size([1, 12, 197, 64])\n",
      "blocks.11.attn.hook_attn_scores torch.Size([1, 12, 197, 197])\n",
      "blocks.11.attn.hook_pattern torch.Size([1, 12, 197, 197])\n",
      "blocks.11.attn.hook_z torch.Size([1, 12, 197, 64])\n",
      "blocks.11.hook_attn_out torch.Size([1, 197, 768])\n",
      "blocks.11.hook_resid_mid torch.Size([1, 197, 768])\n",
      "blocks.11.ln2.hook_scale torch.Size([1, 197, 1])\n",
      "blocks.11.ln2.hook_normalized torch.Size([1, 197, 768])\n",
      "blocks.11.mlp.hook_pre torch.Size([1, 197, 3072])\n",
      "blocks.11.mlp.hook_post torch.Size([1, 197, 3072])\n",
      "blocks.11.hook_mlp_out torch.Size([1, 197, 768])\n",
      "blocks.11.hook_resid_post torch.Size([1, 197, 768])\n",
      "ln_final.hook_scale torch.Size([1, 197, 1])\n",
      "ln_final.hook_normalized torch.Size([1, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "image, label = next(iter(testloader))\n",
    "output, cache = prisma_model.run_with_cache(image)\n",
    "\n",
    "for key in cache.keys():\n",
    "    print(key, cache[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.patch_embed.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "activations[0].shape\n",
    "\n",
    "assert torch.allclose(activations[0], cache['embed'][0])\n",
    "assert torch.all(activations[0] == cache['embed'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.pos_drop.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "assert torch.allclose(activations[0], cache['blocks.0.hook_resid_pre'], atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LayerNorm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "# Pre norm\n",
    "import einops \n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.norm_pre.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "# # Repeat the above 12 times (adding head dimension)\n",
    "# repeated_tensor = einops.repeat(\n",
    "#             activations[0],\n",
    "#             \"batch pos d_model -> batch pos n_heads d_model\",\n",
    "#             n_heads=12,\n",
    "#         )\n",
    "\n",
    "# print(repeated_tensor[0].shape)\n",
    "print(cache['blocks.0.hook_attn_in'].shape)\n",
    "\n",
    "assert torch.allclose(activations[0], cache['blocks.0.hook_attn_in'][0], atol=1), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 197, 768])\n",
      "torch.Size([1, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import einops \n",
    "\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.blocks[0].norm1.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "print(activations[0].shape)\n",
    "print(cache['blocks.0.ln1.hook_normalized'].shape)\n",
    "\n",
    "# Assert equal to the first layer\n",
    "assert torch.allclose(activations[0], cache['blocks.0.ln1.hook_normalized'][0], atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "**Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's compare qkv weights\n",
    "# QKV = timm_model.blocks[0].attn.qkv.weight\n",
    "# W_Q, W_K, W_V = torch.tensor_split(QKV, 3, dim=0)\n",
    "# t_Q = einops.rearrange(W_Q, \"(i h) m->h m i\", h=12)\n",
    "# t_K = einops.rearrange(W_K, \"(i h) m->h m i\", h=12)\n",
    "# t_V = einops.rearrange(W_V, \"(i h) m->h m i\", h=12)\n",
    "\n",
    "# p_Q = prisma_model.blocks[0].attn.W_Q\n",
    "# p_K = prisma_model.blocks[0].attn.W_K\n",
    "# p_V = prisma_model.blocks[0].attn.W_V\n",
    "\n",
    "# assert torch.allclose(p_Q, t_Q, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "# assert torch.allclose(p_K, t_K, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "# assert torch.allclose(p_V, t_V, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "\n",
    "# # qkv bias\n",
    "# bias_QKV = timm_model.blocks[0].attn.qkv.bias\n",
    "\n",
    "# b_Q, b_K, b_V = torch.tensor_split(bias_QKV, 3, dim=0)\n",
    "\n",
    "# bt_Q = einops.rearrange(b_Q, \"(i h) -> h i\", h=12)\n",
    "# bt_K = einops.rearrange(b_K, \"(i h) -> h i\", h=12)\n",
    "# bt_V = einops.rearrange(b_V, \"(i h) -> h i\", h=12)\n",
    "\n",
    "# bp_Q = prisma_model.blocks[0].attn.b_Q\n",
    "# bp_K = prisma_model.blocks[0].attn.b_K\n",
    "# bp_V = prisma_model.blocks[0].attn.b_V\n",
    "\n",
    "# assert torch.allclose(bp_Q, bt_Q, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "# assert torch.allclose(bp_K, bt_K, atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "# assert torch.allclose(bp_V, bt_V, atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrix_corner(matrix, rows=1, cols=1):\n",
    "    \"\"\"\n",
    "    Prints the top-left corner of a matrix (tensor) up to the specified number of rows and columns.\n",
    "\n",
    "    Parameters:\n",
    "    - matrix (torch.Tensor): The matrix (tensor) from which to print the corner.\n",
    "    - rows (int): The number of rows to include in the printed corner. Default is 5.\n",
    "    - cols (int): The number of columns to include in the printed corner. Default is 5.\n",
    "    \"\"\"\n",
    "    # Ensure the matrix is a PyTorch tensor\n",
    "    if not isinstance(matrix, torch.Tensor):\n",
    "        print(\"The input is not a PyTorch tensor.\")\n",
    "        return\n",
    "\n",
    "    # Get the size of the matrix\n",
    "    num_rows, num_cols = matrix.shape[:2]\n",
    "\n",
    "    # Adjust rows and cols if the matrix is smaller than specified dimensions\n",
    "    rows_to_print = min(rows, num_rows)\n",
    "    cols_to_print = min(cols, num_cols)\n",
    "\n",
    "    # Slice the matrix to get the top-left corner\n",
    "    corner = matrix[:rows_to_print, :cols_to_print]\n",
    "\n",
    "    print(f\"Top-left corner ({rows_to_print}x{cols_to_print}):\\n{corner}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QKV matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timm output torch.Size([1, 197, 2304])\n",
      "timm shape torch.Size([3, 1, 12, 197, 64])\n",
      "prisma shape torch.Size([3, 1, 12, 197, 64])\n",
      "prisma q shape torch.Size([1, 12, 197, 64])\n"
     ]
    }
   ],
   "source": [
    "# First layer\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.blocks[0].attn.qkv.register_forward_hook(hook_fn)\n",
    "\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "print(\"timm output\", activations[0].shape)\n",
    "qkv = activations[0].reshape(-1, 197, 3, 12, 64).permute(2, 0, 3, 1, 4)\n",
    "q, k, v = qkv.unbind(0)\n",
    "\n",
    "print(\"timm shape\", qkv.shape)\n",
    "print(\"prisma shape\", cache['blocks.0.attn.hook_qkv'].shape)\n",
    "\n",
    "print(\"prisma q shape\", cache['blocks.0.attn.hook_q'].shape)\n",
    "\n",
    "assert torch.allclose(qkv, cache['blocks.0.attn.hook_qkv'], atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "assert torch.allclose(q, cache['blocks.0.attn.hook_q'], atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "assert torch.allclose(k, cache['blocks.0.attn.hook_k'], atol=1e-6), \"Activations differ more than the allowed tolerance\"\n",
    "assert torch.allclose(v, cache['blocks.0.attn.hook_v'], atol=1e-6), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timm attn scores torch.Size([1, 12, 197, 197])\n",
      "prisma attn scores torch.Size([1, 12, 197, 197])\n"
     ]
    }
   ],
   "source": [
    "scaled_q = q * 64 ** -0.5\n",
    "timm_attn_scores = scaled_q @ k.transpose(-2,-1)\n",
    "\n",
    "print(\"timm attn scores\", timm_attn_scores.shape)\n",
    "print(\"prisma attn scores\", cache['blocks.0.attn.hook_attn_scores'].shape)\n",
    "\n",
    "assert torch.allclose(timm_attn_scores, cache['blocks.0.attn.hook_attn_scores'], atol=1e-4), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm_attn_pattern = timm_attn_scores.softmax(dim=-1) \n",
    "\n",
    "assert torch.allclose(timm_attn_pattern, cache['blocks.0.attn.hook_pattern'], atol=1e-4), \"Activations differ more than the allowed tolerance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "# First layer\n",
    "activations = []\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hook_handle = timm_model.blocks[0].attn.proj.register_forward_hook(hook_fn)\n",
    "timm_output = timm_model(image)\n",
    "hook_handle.remove()\n",
    "\n",
    "print(activations[0].shape)\n",
    "# print(cache['blocks.0.attn.hook_attn_out'].shape)\n",
    "\n",
    "\n",
    "assert torch.allclose(cache['blocks.0.attn.hook_result'], activations[0], atol=1e-3), \"Activations differ more than the allowed tolerance\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
