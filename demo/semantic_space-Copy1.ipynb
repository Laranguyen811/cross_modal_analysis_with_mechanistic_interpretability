{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis on the Semantic Space of a Vision Transformer\n",
    "\n",
    "We want to see the semantic space of TinyCLIP using ablations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vit_prisma \n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model\n",
    "\n",
    "We're just using the visual encoder of TinyCLIP. The visual encoder is a transformer with 10 layers, 12 attention heads, and 256 hidden representation dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vit_prisma.models.base_vit import HookedViT\n",
    "# import torch\n",
    "\n",
    "# TOLERANCE = 1e-5\n",
    "\n",
    "# model_name = \"vit_base_patch32_224\"\n",
    "# batch_size = 5\n",
    "# channels = 3\n",
    "# height = 224\n",
    "# width = 224\n",
    "# device = \"cpu\"\n",
    "\n",
    "# hooked_model = HookedViT.from_pretrained(model_name)\n",
    "# hooked_model.to(device)\n",
    "# timm_model = timm.create_model(model_name, pretrained=True)\n",
    "# timm_model.to(device)\n",
    "\n",
    "# with torch.random.fork_rng():\n",
    "#     torch.manual_seed(1)\n",
    "#     input_image = torch.rand((batch_size, channels, height, width)).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert torch.allclose(hooked_model(input_image), timm_model(input_image), atol=TOLERANCE), \"Model output diverges!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CIFAR-100\n",
    "\n",
    "The labels of CIFAR-100 have two levels of granularity: coarse-grained and fine-grained labels. \n",
    "\n",
    "We want to see the relationship between the coarse-grained and fine-grained labels inside the net. For example, perhaps the coarse-grained labels tend to be identified around Layer 5, while the fine-grained labels tend to be identified around Label 6. Perhaps there is a semantic hierarchy reflected in a TinyCLIP circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1834be8b8524ab482a63542fcc37681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/146M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3f88212f5f4eb891a8fee7dc96251c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8885033c6a6486792750b4232aea9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6525edc3374366864334c86cc1cab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7FE378C47160>, 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "tiny_imagenet = load_dataset('Maysee/tiny-imagenet', split='train')\n",
    "print(tiny_imagenet[0])\n",
    "\n",
    "class HuggingFaceDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hf_dataset: The Hugging Face dataset object.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch the image and label from the Hugging Face dataset\n",
    "        item = self.hf_dataset[idx]\n",
    "        image = item['image']\n",
    "        label = item['label']\n",
    "\n",
    "        # Apply transformations to the image if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert image to tensor if it's a PIL Image\n",
    "        if isinstance(image, Image.Image):\n",
    "            image = transforms.ToTensor()(image)\n",
    "\n",
    "        return image, torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtiny_imagenet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "tiny_imagenet.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layers': 12, 'd_model': 768, 'd_head': 64, 'model_name': 'timm/vit_base_patch32_224.augreg_in21k_ft_in1k', 'n_heads': 12, 'd_mlp': 3072, 'activation_name': 'gelu', 'eps': 1e-06, 'original_architecture': 'vit_base_patch32_224', 'initializer_range': 0.02, 'n_channels': 3, 'patch_size': 32, 'image_size': 224, 'n_classes': 1000, 'n_params': 88224232, 'return_type': 'class_logits'}\n",
      "Loaded pretrained model vit_base_patch32_224 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "# Finetune the model so it's performing well on CIFAR-100\n",
    "from vit_prisma.models.base_vit import HookedViT\n",
    "\n",
    "model_name = \"vit_base_patch32_224\"\n",
    "hooked_model = HookedViT.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = HuggingFaceDataset(tiny_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"n01443537\", \"n01629819\", \"n01641577\", \"n01644900\", \"n01698640\", \"n01742172\", \"n01768244\", \"n01770393\", \"n01774384\", \"n01774750\", \"n01784675\", \"n01882714\", \"n01910747\", \"n01917289\", \"n01944390\", \"n01950731\", \"n01983481\", \"n01984695\", \"n02002724\", \"n02056570\", \"n02058221\", \"n02074367\", \"n02094433\", \"n02099601\", \"n02099712\", \"n02106662\", \"n02113799\", \"n02123045\", \"n02123394\", \"n02124075\", \"n02125311\", \"n02129165\", \"n02132136\", \"n02165456\", \"n02226429\", \"n02231487\", \"n02233338\", \"n02236044\", \"n02268443\", \"n02279972\", \"n02281406\", \"n02321529\", \"n02364673\", \"n02395406\", \"n02403003\", \"n02410509\", \"n02415577\", \"n02423022\", \"n02437312\", \"n02480495\", \"n02481823\", \"n02486410\", \"n02504458\", \"n02509815\", \"n02666347\", \"n02669723\", \"n02699494\", \"n02769748\", \"n02788148\", \"n02791270\", \"n02793495\", \"n02795169\", \"n02802426\", \"n02808440\", \"n02814533\", \"n02814860\", \"n02815834\", \"n02823428\", \"n02837789\", \"n02841315\", \"n02843684\", \"n02883205\", \"n02892201\", \"n02909870\", \"n02917067\", \"n02927161\", \"n02948072\", \"n02950826\", \"n02963159\", \"n02977058\", \"n02988304\", \"n03014705\", \"n03026506\", \"n03042490\", \"n03085013\", \"n03089624\", \"n03100240\", \"n03126707\", \"n03160309\", \"n03179701\", \"n03201208\", \"n03255030\", \"n03355925\", \"n03373237\", \"n03388043\", \"n03393912\", \"n03400231\", \"n03404251\", \"n03424325\", \"n03444034\", \"n03447447\", \"n03544143\", \"n03584254\", \"n03599486\", \"n03617480\", \"n03637318\", \"n03649909\", \"n03662601\", \"n03670208\", \"n03706229\", \"n03733131\", \"n03763968\", \"n03770439\", \"n03796401\", \"n03814639\", \"n03837869\", \"n03838899\", \"n03854065\", \"n03891332\", \"n03902125\", \"n03930313\", \"n03937543\", \"n03970156\", \"n03977966\", \"n03980874\", \"n03983396\", \"n03992509\", \"n04008634\", \"n04023962\", \"n04070727\", \"n04074963\", \"n04099969\", \"n04118538\", \"n04133789\", \"n04146614\", \"n04149813\", \"n04179913\", \"n04251144\", \"n04254777\", \"n04259630\", \"n04265275\", \"n04275548\", \"n04285008\", \"n04311004\", \"n04328186\", \"n04356056\", \"n04366367\", \"n04371430\", \"n04376876\", \"n04398044\", \"n04399382\", \"n04417672\", \"n04456115\", \"n04465666\", \"n04486054\", \"n04487081\", \"n04501370\", \"n04507155\", \"n04532106\", \"n04532670\", \"n04540053\", \"n04560804\", \"n04562935\", \"n04596742\", \"n04598010\", \"n06596364\", \"n07056680\", \"n07583066\", \"n07614500\", \"n07615774\", \"n07646821\", \"n07647870\", \"n07657664\", \"n07695742\", \"n07711569\", \"n07715103\", \"n07720875\", \"n07749582\", \"n07753592\", \"n07768694\", \"n07871810\", \"n07873807\", \"n07875152\", \"n07920052\", \"n07975909\", \"n08496334\", \"n08620881\", \"n08742578\", \"n09193705\", \"n09246464\", \"n09256479\", \"n09332890\", \"n09428293\", \"n12267677\", \"n12520864\", \"n13001041\", \"n13652335\", \"n13652994\", \"n13719102\", \"n14991210\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 35363  100 35363    0     0   145k      0 --:--:-- --:--:-- --:--:--  145k\n"
     ]
    }
   ],
   "source": [
    "# Get ImageNet IDs\n",
    "!curl -O https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import certifi\n",
    "\n",
    "# Set the REQUESTS_CA_BUNDLE environment variable to the certifi CA bundle path\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = certifi.where()\n",
    "os.environ['SSL_CERT_DIR'] = '/etc/ssl/certs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNID: n01440764, Class Name: tench\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the class index file\n",
    "with open('imagenet_class_index.json', 'r') as f:\n",
    "    class_index = json.load(f)\n",
    "\n",
    "# Example: Get the class name and WNID for a specific index\n",
    "index = '0'  # The index is a string in the JSON keys\n",
    "wnid, class_name = class_index[index]\n",
    "print(f\"WNID: {wnid}, Class Name: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/mila/s/sonia.joseph/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n01443537\n",
      "['goldfish', 'Carassius_auratus']\n",
      "n01629819\n",
      "['European_fire_salamander', 'Salamandra_salamandra']\n",
      "n01641577\n",
      "['bullfrog', 'Rana_catesbeiana']\n",
      "n01644900\n",
      "['tailed_frog', 'bell_toad', 'ribbed_toad', 'tailed_toad', 'Ascaphus_trui']\n",
      "n01698640\n",
      "['American_alligator', 'Alligator_mississipiensis']\n",
      "n01742172\n",
      "['boa_constrictor', 'Constrictor_constrictor']\n",
      "n01768244\n",
      "['trilobite']\n",
      "n01770393\n",
      "['scorpion']\n",
      "n01774384\n",
      "['black_widow', 'Latrodectus_mactans']\n",
      "n01774750\n",
      "['tarantula']\n",
      "n01784675\n",
      "['centipede']\n",
      "n01882714\n",
      "['koala', 'koala_bear', 'kangaroo_bear', 'native_bear', 'Phascolarctos_cinereus']\n",
      "n01910747\n",
      "['jellyfish']\n",
      "n01917289\n",
      "['brain_coral']\n",
      "n01944390\n",
      "['snail']\n",
      "n01950731\n",
      "['sea_slug', 'nudibranch']\n",
      "n01983481\n",
      "['American_lobster', 'Northern_lobster', 'Maine_lobster', 'Homarus_americanus']\n",
      "n01984695\n",
      "['spiny_lobster', 'langouste', 'rock_lobster', 'crawfish', 'crayfish', 'sea_crawfish']\n",
      "n02002724\n",
      "['black_stork', 'Ciconia_nigra']\n",
      "n02056570\n",
      "['king_penguin', 'Aptenodytes_patagonica']\n",
      "n02058221\n",
      "['albatross', 'mollymawk']\n",
      "n02074367\n",
      "['dugong', 'Dugong_dugon']\n",
      "n02094433\n",
      "['Yorkshire_terrier']\n",
      "n02099601\n",
      "['golden_retriever']\n",
      "n02099712\n",
      "['Labrador_retriever']\n",
      "n02106662\n",
      "['German_shepherd', 'German_shepherd_dog', 'German_police_dog', 'alsatian']\n",
      "n02113799\n",
      "['standard_poodle']\n",
      "n02123045\n",
      "['tabby', 'tabby_cat']\n",
      "n02123394\n",
      "['Persian_cat']\n",
      "n02124075\n",
      "['Egyptian_cat']\n",
      "n02125311\n",
      "['cougar', 'puma', 'catamount', 'mountain_lion', 'painter', 'panther', 'Felis_concolor']\n",
      "n02129165\n",
      "['lion', 'king_of_beasts', 'Panthera_leo']\n",
      "n02132136\n",
      "['brown_bear', 'bruin', 'Ursus_arctos']\n",
      "n02165456\n",
      "['ladybug', 'ladybeetle', 'lady_beetle', 'ladybird', 'ladybird_beetle']\n",
      "n02226429\n",
      "['grasshopper', 'hopper']\n",
      "n02231487\n",
      "['walking_stick', 'walkingstick', 'stick_insect']\n",
      "n02233338\n",
      "['cockroach', 'roach']\n",
      "n02236044\n",
      "['mantis', 'mantid']\n",
      "n02268443\n",
      "['dragonfly', 'darning_needle', \"devil's_darning_needle\", 'sewing_needle', 'snake_feeder', 'snake_doctor', 'mosquito_hawk', 'skeeter_hawk']\n",
      "n02279972\n",
      "['monarch', 'monarch_butterfly', 'milkweed_butterfly', 'Danaus_plexippus']\n",
      "n02281406\n",
      "['sulphur_butterfly', 'sulfur_butterfly']\n",
      "n02321529\n",
      "['sea_cucumber', 'holothurian']\n",
      "n02364673\n",
      "['guinea_pig', 'Cavia_cobaya']\n",
      "n02395406\n",
      "['hog', 'pig', 'grunter', 'squealer', 'Sus_scrofa']\n",
      "n02403003\n",
      "['ox']\n",
      "n02410509\n",
      "['bison']\n",
      "n02415577\n",
      "['bighorn', 'bighorn_sheep', 'cimarron', 'Rocky_Mountain_bighorn', 'Rocky_Mountain_sheep', 'Ovis_canadensis']\n",
      "n02423022\n",
      "['gazelle']\n",
      "n02437312\n",
      "['Arabian_camel', 'dromedary', 'Camelus_dromedarius']\n",
      "n02480495\n",
      "['orangutan', 'orang', 'orangutang', 'Pongo_pygmaeus']\n",
      "n02481823\n",
      "['chimpanzee', 'chimp', 'Pan_troglodytes']\n",
      "n02486410\n",
      "['baboon']\n",
      "n02504458\n",
      "['African_elephant', 'Loxodonta_africana']\n",
      "n02509815\n",
      "['lesser_panda', 'red_panda', 'panda', 'bear_cat', 'cat_bear', 'Ailurus_fulgens']\n",
      "n02666347\n",
      "['abacus']\n",
      "n02669723\n",
      "['academic_gown', 'academic_robe', \"judge's_robe\"]\n",
      "n02699494\n",
      "['altar']\n",
      "n02769748\n",
      "['backpack', 'back_pack', 'knapsack', 'packsack', 'rucksack', 'haversack']\n",
      "n02788148\n",
      "['bannister', 'banister', 'balustrade', 'balusters', 'handrail']\n",
      "n02791270\n",
      "['barbershop']\n",
      "n02793495\n",
      "['barn']\n",
      "n02795169\n",
      "['barrel', 'cask']\n",
      "n02802426\n",
      "['basketball']\n",
      "n02808440\n",
      "['bathtub', 'bathing_tub', 'bath', 'tub']\n",
      "n02814533\n",
      "['beach_wagon', 'station_wagon', 'wagon', 'estate_car', 'beach_waggon', 'station_waggon', 'waggon']\n",
      "n02814860\n",
      "['beacon', 'lighthouse', 'beacon_light', 'pharos']\n",
      "n02815834\n",
      "['beaker']\n",
      "n02823428\n",
      "['beer_bottle']\n",
      "n02837789\n",
      "['bikini', 'two-piece']\n",
      "n02841315\n",
      "['binoculars', 'field_glasses', 'opera_glasses']\n",
      "n02843684\n",
      "['birdhouse']\n",
      "n02883205\n",
      "['bow_tie', 'bow-tie', 'bowtie']\n",
      "n02892201\n",
      "['brass', 'memorial_tablet', 'plaque']\n",
      "n02909870\n",
      "['bucket', 'pail']\n",
      "n02917067\n",
      "['bullet_train', 'bullet']\n",
      "n02927161\n",
      "['butcher_shop', 'meat_market']\n",
      "n02948072\n",
      "['candle', 'taper', 'wax_light']\n",
      "n02950826\n",
      "['cannon']\n",
      "n02963159\n",
      "['cardigan']\n",
      "n02977058\n",
      "['cash_machine', 'cash_dispenser', 'automated_teller_machine', 'automatic_teller_machine', 'automated_teller', 'automatic_teller', 'ATM']\n",
      "n02988304\n",
      "['CD_player']\n",
      "n03014705\n",
      "['chest']\n",
      "n03026506\n",
      "['Christmas_stocking']\n",
      "n03042490\n",
      "['cliff_dwelling']\n",
      "n03085013\n",
      "['computer_keyboard', 'keypad']\n",
      "n03089624\n",
      "['confectionery', 'confectionary', 'candy_store']\n",
      "n03100240\n",
      "['convertible']\n",
      "n03126707\n",
      "['crane']\n",
      "n03160309\n",
      "['dam', 'dike', 'dyke']\n",
      "n03179701\n",
      "['desk']\n",
      "n03201208\n",
      "['dining_table', 'board']\n",
      "n03255030\n",
      "['dumbbell']\n",
      "n03355925\n",
      "['flagpole', 'flagstaff']\n",
      "n03373237\n",
      "['fly']\n",
      "n03388043\n",
      "['fountain']\n",
      "n03393912\n",
      "['freight_car']\n",
      "n03400231\n",
      "['frying_pan', 'frypan', 'skillet']\n",
      "n03404251\n",
      "['fur_coat']\n",
      "n03424325\n",
      "['gasmask', 'respirator', 'gas_helmet']\n",
      "n03444034\n",
      "['go-kart']\n",
      "n03447447\n",
      "['gondola']\n",
      "n03544143\n",
      "['hourglass']\n",
      "n03584254\n",
      "['iPod']\n",
      "n03599486\n",
      "['jinrikisha', 'ricksha', 'rickshaw']\n",
      "n03617480\n",
      "['kimono']\n",
      "n03637318\n",
      "['lampshade', 'lamp_shade']\n",
      "n03649909\n",
      "['lawn_mower', 'mower']\n",
      "n03662601\n",
      "['lifeboat']\n",
      "n03670208\n",
      "['limousine', 'limo']\n",
      "n03706229\n",
      "['magnetic_compass']\n",
      "n03733131\n",
      "['maypole']\n",
      "n03763968\n",
      "['military_uniform']\n",
      "n03770439\n",
      "['miniskirt', 'mini']\n",
      "n03796401\n",
      "['moving_van']\n",
      "n03814639\n",
      "['neck_brace']\n",
      "n03837869\n",
      "['obelisk']\n",
      "n03838899\n",
      "['oboe', 'hautboy', 'hautbois']\n",
      "n03854065\n",
      "['organ', 'pipe_organ']\n",
      "n03891332\n",
      "['parking_meter']\n",
      "n03902125\n",
      "['pay-phone', 'pay-station']\n",
      "n03930313\n",
      "['picket_fence', 'paling']\n",
      "n03937543\n",
      "['pill_bottle']\n",
      "n03970156\n",
      "['plunger', \"plumber's_helper\"]\n",
      "n03977966\n",
      "['police_van', 'police_wagon', 'paddy_wagon', 'patrol_wagon', 'wagon', 'black_Maria']\n",
      "n03980874\n",
      "['poncho']\n",
      "n03983396\n",
      "['pop_bottle', 'soda_bottle']\n",
      "n03992509\n",
      "[\"potter's_wheel\"]\n",
      "n04008634\n",
      "['projectile', 'missile']\n",
      "n04023962\n",
      "['punching_bag', 'punch_bag', 'punching_ball', 'punchball']\n",
      "n04070727\n",
      "['refrigerator', 'icebox']\n",
      "n04074963\n",
      "['remote_control', 'remote']\n",
      "n04099969\n",
      "['rocking_chair', 'rocker']\n",
      "n04118538\n",
      "['rugby_ball']\n",
      "n04133789\n",
      "['sandal']\n",
      "n04146614\n",
      "['school_bus']\n",
      "n04149813\n",
      "['scoreboard']\n",
      "n04179913\n",
      "['sewing_machine']\n",
      "n04251144\n",
      "['snorkel']\n",
      "n04254777\n",
      "['sock']\n",
      "n04259630\n",
      "['sombrero']\n",
      "n04265275\n",
      "['space_heater']\n",
      "n04275548\n",
      "['spider_web', \"spider's_web\"]\n",
      "n04285008\n",
      "['sports_car', 'sport_car']\n",
      "n04311004\n",
      "['steel_arch_bridge']\n",
      "n04328186\n",
      "['stopwatch', 'stop_watch']\n",
      "n04356056\n",
      "['sunglasses', 'dark_glasses', 'shades']\n",
      "n04366367\n",
      "['suspension_bridge']\n",
      "n04371430\n",
      "['swimming_trunks', 'bathing_trunks']\n",
      "n04376876\n",
      "['syringe']\n",
      "n04398044\n",
      "['teapot']\n",
      "n04399382\n",
      "['teddy', 'teddy_bear']\n",
      "n04417672\n",
      "['thatch', 'thatched_roof']\n",
      "n04456115\n",
      "['torch']\n",
      "n04465666\n",
      "['tractor']\n",
      "n04486054\n",
      "['triumphal_arch']\n",
      "n04487081\n",
      "['trolleybus', 'trolley_coach', 'trackless_trolley']\n",
      "n04501370\n",
      "['turnstile']\n",
      "n04507155\n",
      "['umbrella']\n",
      "n04532106\n",
      "['vestment']\n",
      "n04532670\n",
      "['viaduct']\n",
      "n04540053\n",
      "['volleyball']\n",
      "n04560804\n",
      "['water_jug']\n",
      "n04562935\n",
      "['water_tower']\n",
      "n04596742\n",
      "['wok']\n",
      "n04598010\n",
      "['wooden_spoon']\n",
      "n06596364\n",
      "['comic_book']\n",
      "n07056680\n",
      "['reel']\n",
      "n07583066\n",
      "['guacamole']\n",
      "n07614500\n",
      "['ice_cream', 'icecream']\n",
      "n07615774\n",
      "['ice_lolly', 'lolly', 'lollipop', 'popsicle']\n",
      "n07646821\n",
      "['goose']\n",
      "n07647870\n",
      "['drumstick']\n",
      "n07657664\n",
      "['plate']\n",
      "n07695742\n",
      "['pretzel']\n",
      "n07711569\n",
      "['mashed_potato']\n",
      "n07715103\n",
      "['cauliflower']\n",
      "n07720875\n",
      "['bell_pepper']\n",
      "n07749582\n",
      "['lemon']\n",
      "n07753592\n",
      "['banana']\n",
      "n07768694\n",
      "['pomegranate']\n",
      "n07871810\n",
      "['meat_loaf', 'meatloaf']\n",
      "n07873807\n",
      "['pizza', 'pizza_pie']\n",
      "n07875152\n",
      "['potpie']\n",
      "n07920052\n",
      "['espresso']\n",
      "n07975909\n",
      "['bee']\n",
      "n08496334\n",
      "['apron']\n",
      "n08620881\n",
      "['pole']\n",
      "n08742578\n",
      "['Chihuahua']\n",
      "n09193705\n",
      "['alp']\n",
      "n09246464\n",
      "['cliff', 'drop', 'drop-off']\n",
      "n09256479\n",
      "['coral_reef']\n",
      "n09332890\n",
      "['lakeside', 'lakeshore']\n",
      "n09428293\n",
      "['seashore', 'coast', 'seacoast', 'sea-coast']\n",
      "n12267677\n",
      "['acorn']\n",
      "n12520864\n",
      "['broom']\n",
      "n13001041\n",
      "['mushroom']\n",
      "n13652335\n",
      "['nail']\n",
      "n13652994\n",
      "['chain']\n",
      "n13719102\n",
      "['slug']\n",
      "n14991210\n",
      "['orange']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "for i in range(len(names)):\n",
    "    wnid = names[i]\n",
    "\n",
    "    print(wnid)\n",
    "\n",
    "    # Correct approach: Convert WNID to offset and use synset_from_pos_and_offset\n",
    "    offset = int(wnid[1:])  # Extract the numerical part of the WNID and convert to integer\n",
    "    pos = 'n'  # 'n' for noun, which is typical for WNIDs\n",
    "\n",
    "    # Fetch the synset using the offset and part of speech\n",
    "    synset = wn.synset_from_pos_and_offset(pos, offset)\n",
    "\n",
    "    # Get the lemma names (human-readable names)\n",
    "    eng_names = synset.lemma_names()\n",
    "    print(eng_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('abyssinian.n.01'), Synset('alley_cat.n.01'), Synset('angora.n.04'), Synset('burmese_cat.n.01'), Synset('egyptian_cat.n.01'), Synset('kitty.n.04'), Synset('maltese.n.03'), Synset('manx.n.02'), Synset('mouser.n.01'), Synset('persian_cat.n.01'), Synset('siamese_cat.n.01'), Synset('tabby.n.01'), Synset('tabby.n.02'), Synset('tiger_cat.n.02'), Synset('tom.n.02'), Synset('tortoiseshell.n.03')]\n",
      "Synset('abyssinian.n.01')\n",
      "Synset('alley_cat.n.01')\n",
      "Synset('angora.n.04')\n",
      "Synset('burmese_cat.n.01')\n",
      "Synset('egyptian_cat.n.01')\n",
      "Synset('kitty.n.04')\n",
      "Synset('maltese.n.03')\n",
      "Synset('manx.n.02')\n",
      "Synset('mouser.n.01')\n",
      "Synset('persian_cat.n.01')\n"
     ]
    }
   ],
   "source": [
    "tabby_cat = 'n02121808'\n",
    "\n",
    "# Find the synset for \"cat\"\n",
    "# cat_synset = wn.synset(tabby_cat)  # This is an illustrative example; use the correct synset\n",
    "\n",
    "# Correct approach: Convert WNID to offset and use synset_from_pos_and_offset\n",
    "offset = int(tabby_cat[1:])  # Extract the numerical part of the WNID and convert to integer\n",
    "pos = 'n'  # 'n' for noun, which is typical for WNIDs\n",
    "\n",
    "# Fetch the synset using the offset and part of speech\n",
    "cat_synset = wn.synset_from_pos_and_offset(pos, offset)\n",
    "\n",
    "# Get the lemma names (human-readable names)\n",
    "# eng_names = synset.lemma_names()\n",
    "# print(eng_names)\n",
    "    \n",
    "# Find all hyponyms of the cat synset\n",
    "cat_hyponyms = cat_synset.hyponyms()\n",
    "\n",
    "print(cat_hyponyms)\n",
    "\n",
    "# Print out some of the hyponyms\n",
    "for hyponym in cat_hyponyms[:10]:  #\n",
    "    print(hyponym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Felidae WNIDs: 0\n",
      "Some example WNIDs: []\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Define a function to recursively accumulate all descendant hyponyms of a given synset\n",
    "def accumulate_descendant_hyponyms(synset, accumulated_hyponyms=None):\n",
    "    if accumulated_hyponyms is None:\n",
    "        accumulated_hyponyms = set()\n",
    "    for hyponym in synset.hyponyms():\n",
    "        accumulated_hyponyms.add(hyponym)\n",
    "        accumulate_descendant_hyponyms(hyponym, accumulated_hyponyms)\n",
    "    return accumulated_hyponyms\n",
    "\n",
    "# Fetch the Felidae synset\n",
    "felidae_synset = wn.synset('felidae.n.01')\n",
    "\n",
    "# Use the function to accumulate all descendant hyponyms of Felidae\n",
    "all_felidae_hyponyms = accumulate_descendant_hyponyms(felidae_synset)\n",
    "\n",
    "# Extract WNIDs for these hyponyms\n",
    "felidae_wnids = [\"n\" + str(hyponym.offset()).zfill(8) for hyponym in all_felidae_hyponyms]\n",
    "\n",
    "print(f\"Number of Felidae WNIDs: {len(felidae_wnids)}\")\n",
    "print(\"Some example WNIDs:\", felidae_wnids[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superclass(class_name, superclasses):\n",
    "    \"\"\"\n",
    "    Return the superclass of a given class name from CIFAR-100.\n",
    "\n",
    "    Parameters:\n",
    "    - class_name: The name of the class for which to find the superclass.\n",
    "    - superclasses: A dictionary where keys are superclasses and values are lists of classes.\n",
    "\n",
    "    Returns:\n",
    "    - The name of the superclass if found, otherwise \"Class not found\".\n",
    "    \"\"\"\n",
    "    for superclass, classes in superclasses.items():\n",
    "        if class_name in classes:\n",
    "            return superclass\n",
    "    return \"Class not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ballast.n.03: an attribute that tends to give stability in character and morals; something that steadies the mind or feelings\n",
      "character.n.09: (genetics) an attribute (structural or functional) that is determined by a gene or group of genes\n",
      "cheerfulness.n.01: the quality of being cheerful and dispelling gloom\n",
      "common_denominator.n.02: an attribute that is common to all members of a category\n",
      "depth.n.06: the attribute or quality of being deep, strong, or intense\n",
      "eidos.n.01: (anthropology) the distinctive expression of the cognitive or intellectual character of a culture or a social group\n",
      "ethos.n.01: (anthropology) the distinctive spirit of a culture or an era\n",
      "human_nature.n.01: the shared psychological attributes of humankind that are assumed to be shared by all human beings\n",
      "inheritance.n.04: any attribute or immaterial possession that is inherited from ancestors\n",
      "personality.n.01: the complex of all the attributes--behavioral, temperamental, emotional and mental--that characterize a unique individual\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def find_labels_at_level(synset, level, current_level=0):\n",
    "    \"\"\"\n",
    "    Recursively find all labels (synsets) at a given level of the hierarchy.\n",
    "\n",
    "    Args:\n",
    "    - synset: The current synset from which to explore.\n",
    "    - level: The target level depth to find synsets.\n",
    "    - current_level: The current level depth in the recursion.\n",
    "\n",
    "    Returns:\n",
    "    - A list of synsets found at the specified level.\n",
    "    \"\"\"\n",
    "    # Base case: If the current level matches the target level, return the current synset\n",
    "    if current_level == level:\n",
    "        return [synset]\n",
    "    \n",
    "    # Recursive case: Explore child synsets (hyponyms) if not at the target level yet\n",
    "    elif current_level < level:\n",
    "        labels = []\n",
    "        for hyponym in synset.hyponyms():\n",
    "            labels.extend(find_labels_at_level(hyponym, level, current_level + 1))\n",
    "        return labels\n",
    "    \n",
    "    # If current level is somehow greater than target (should not happen in correct use), return empty list\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "root_synset = wn.synset('entity.n.01')  # Start from the root noun synset\n",
    "level = 3  # Specify the target level depth\n",
    "labels_at_level = find_labels_at_level(root_synset, level)\n",
    "\n",
    "# Print out some results\n",
    "for synset in labels_at_level[:10]:  # Limiting output for brevity\n",
    "    print(f\"{synset.name()}: {synset.definition()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_list=[[\"-\" for j in range(7)] for i in range(200)]\n",
    "for i in range(200):\n",
    "    wnid = names[i]\n",
    "\n",
    "    # Correct approach: Convert WNID to offset and use synset_from_pos_and_offset\n",
    "    offset = int(wnid[1:])  # Extract the numerical part of the WNID and convert to integer\n",
    "    pos = 'n'  # 'n' for noun, which is typical for WNIDs\n",
    "    synset=wn.synset_from_pos_and_offset(pos, offset)\n",
    "    hyper_list=[]\n",
    "    while synset.hypernyms():\n",
    "        synset = synset.hypernyms()[0]\n",
    "        hyper_list.append(synset.name())\n",
    "    hyper_list.insert(0,'null')\n",
    "    hyper_list.insert(0,'null')\n",
    "    all_list[i][:]=hyper_list[:-7:-1]\n",
    "\n",
    "df=pd.DataFrame(all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5\n",
       "instrumentality.n.03      68\n",
       "organism.n.01             56\n",
       "structure.n.01            18\n",
       "commodity.n.01            16\n",
       "covering.n.02              6\n",
       "nutriment.n.01             5\n",
       "plant_part.n.01            4\n",
       "null                       3\n",
       "produce.n.01               3\n",
       "linear_unit.n.01           2\n",
       "meat.n.01                  2\n",
       "social_gathering.n.01      1\n",
       "mountain.n.01              1\n",
       "mass_unit.n.01             1\n",
       "geographic_point.n.01      1\n",
       "geographical_area.n.01     1\n",
       "ridge.n.01                 1\n",
       "helping.n.01               1\n",
       "beverage.n.01              1\n",
       "baked_goods.n.01           1\n",
       "block.n.01                 1\n",
       "foodstuff.n.02             1\n",
       "dance_music.n.02           1\n",
       "award.n.02                 1\n",
       "plaything.n.01             1\n",
       "sheet.n.06                 1\n",
       "coloring_material.n.01     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,5].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prisma_env",
   "language": "python",
   "name": "prisma_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
