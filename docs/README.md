# ViT Prisma 
ViT Prisma is an open-source mechanistic interpretability library for Vision Transformers (ViTs).

We welcome new contributers. Check out our contributing guidelines [here](https://github.com/soniajoseph/ViT-Prisma/blob/main/CONTRIBUTING.md).

## ViT Mice üê≠
ViT Mice are the mini-versions of the standard Vision Transformers.  Just as mice are often used in scientific experiments for the nimble size and ease of iteration, ViT Mice serve a similar purpose to provide insights about their larger counterparts. By training these mice on both toy datasets and in-the-wild data, we aim to observe their behaviors in various environments.

**Categories of ViT Mice** 
1. **Toy Data Mice:** Trained on controlled, synthetic datasets to understand specific behaviors or to isolate certain aspects of the learning process.
2. **In-the-Wild Mice:** Trained on naturalistic, real-world data reminiscent of models in-production.

**List of Mice** 

_To train_
* ImageNet-1k Mice
* Induction Mice
* Modular Arithmetic Mice

**Guidelines for training + uploading models**

Upload your trained models to Huggingface. Follow the [Huggingface guidelines](https://huggingface.co/docs/hub/models-uploading) and also create a model card. Document as much of the training process as possible including dataset, hyperparameters, optimizer, learning rate schedule, and other details that may be relevant.

Include frequent checkpoints throughout training, which will help other researchers understand training dynamics.

## ViT Prisms üåà
Our "Prisms" are the interpretability tools designed to provide insights into the functioning of the ViTs. By viewing a ViT through different prisms, we can uncover different aspects of its operation, from attention patterns to feature visualizations and more.


## ViT Training Code üöÄ

